{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "039327f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### this notebook is for developing the higher-order moment based ICA algorithms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import mat4py\n",
    "import mat73\n",
    "import sounddevice as sd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf857e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### data pre-process functions\n",
    "\n",
    "###### \n",
    "def Center(x):\n",
    "    \"\"\"assume that the data are in R^(dxm) where d is the different components, \n",
    "    m is the number of samples,\n",
    "    return the mean centered data by subtracting the mean of each row from the rows,\n",
    "    i.e. x_i: - E_j[x_ij] for each i = 1,2...,d \n",
    "    \"\"\"\n",
    "    x_center = x- np.mean(x, axis=1, keepdims=True)\n",
    "    return x_center\n",
    "\n",
    "def Cov(x):\n",
    "    \"\"\"return the covariance matrix of data x (centered) in R^(d x m) in the component space, i.e. x.x^t/(m-1)\n",
    "    \"\"\"\n",
    "    d, m = x.shape\n",
    "    x_cov = np.matmul(x, x.T)/(m-1)\n",
    "    return x_cov\n",
    "\n",
    "def SVD_PCA(x):\n",
    "    \"\"\"since x (centered) is in R^(d x m), we actually perform SVD on x^t which is in R^(m x d),\n",
    "    that is, x^t = U.Sigma.V^t, where U is mxd, sigma is dxd diagonal and V^t is dxd,\n",
    "    the rows of V^t (or equivalently, columns of V) are orthogonal eigenvectors of x.x^t,\n",
    "    thus x^t.V are the left singular vectors (proportional to columns in U),\n",
    "    this function returns U, Sigma, V^t of x^t,\n",
    "    and project the x^t into PC space by x^t.V, this is mxd, and taking the transpose for the output in dxm\n",
    "    \"\"\"\n",
    "    U, Sigma, Vt = np.linalg.svd(x.T, full_matrices=False)\n",
    "    PC = np.matmul(x.T, Vt.T).T\n",
    "    return U,Sigma,Vt,PC\n",
    "\n",
    "def Standardize(x):\n",
    "    \"\"\"this function takes the x in R^(d x m) and center it in rows,\n",
    "    and divide each row by the standard deviation, i.e. for each row i, (x-E[x])/std[x] \n",
    "    \"\"\"\n",
    "    d, m = x.shape\n",
    "    x_center = Center(x)\n",
    "    x_std = np.std(x_center, axis=1, ddof=1, keepdims=True)\n",
    "    x_stand = np.divide(x_center, x_std)\n",
    "    return x_stand\n",
    "    \n",
    "def Sigmoid(x):\n",
    "    \"\"\"\n",
    "    A numerically stable sigmoid function for the input x.\n",
    "    \n",
    "    It calculates positive and negative elements with different equations to \n",
    "    prevent overflow by avoid exponentiation with large positive exponent, \n",
    "    thus achieving numerical stability.\n",
    "    \n",
    "    For negative elements in x, sigmoid uses this equation\n",
    "    \n",
    "    $$sigmoid(x_i) = \\frac{e^{x_i}}{1 + e^{x_i}}$$\n",
    "    \n",
    "    For positive elements, it uses another equation:\n",
    "    \n",
    "    $$sigmoid(x_i) = \\frac{1}{e^{-x_i} + 1}$$\n",
    "    \n",
    "    The two equations are equivalent mathematically. \n",
    "    \n",
    "    x is of shape: B x H\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE    \n",
    "    pos_mask = (x >= 0)\n",
    "    neg_mask = (x < 0)\n",
    "\n",
    "    # specify dtype! otherwise, it may all becomes zero, this could have different\n",
    "    # behaviors depending on numpy version\n",
    "    z = np.zeros_like(x, dtype=float)\n",
    "    z[pos_mask] = np.exp(-x[pos_mask])\n",
    "    z[neg_mask] = np.exp(x[neg_mask])\n",
    "\n",
    "    top = np.ones_like(x, dtype=float)\n",
    "    top[neg_mask] = z[neg_mask]\n",
    "    s = top / (1 + z)\n",
    "    ### END YOUR CODE\n",
    "    return s\n",
    "    \n",
    "def MaxLikelihood_ICA(x):\n",
    "    \"\"\"this function takes the x in R^(d x m) whitened data, and apply max likelihood to estimate the matrix W (dxd),\n",
    "    to obtain s = W.x in the end (s in R^(d)), the cdf of s is assumed to be sigmoid in default, the iteration uses \n",
    "    stochastic gradient descent, the initial guess is W, a dxd diagonal matrix 1, \n",
    "    \"\"\"\n",
    "    \n",
    "    d, m = x.shape\n",
    "    W = np.eye(d)\n",
    "    anneal = [0.1, 0.1, 0.1, 0.05, 0.05, 0.05, 0.02, 0.02, 0.01, 0.01,\n",
    "              0.005, 0.005, 0.002, 0.002, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0001, 0.0001]\n",
    "    \n",
    "    for rate in anneal:\n",
    "        print('working on rate = {0}'.format(rate))\n",
    "        X_random = x[:, np.random.permutation(x.shape[1])]\n",
    "        \n",
    "        for j in range(m):\n",
    "\n",
    "            p1 = np.matmul(1 - 2 * Sigmoid(np.dot(W, X_random[:,[j]])), X_random[:,[j]].T)\n",
    "            p2 = np.linalg.inv(W.T)\n",
    "\n",
    "            W += rate*(p1+p2)\n",
    "            #delta = min(delta, np.linalg.norm(W_new-W_old))\n",
    "        \n",
    "\n",
    "    Y = np.matmul(W, x)\n",
    "    return W, Y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1989bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on rate = 0.1\n",
      "working on rate = 0.1\n",
      "working on rate = 0.1\n",
      "working on rate = 0.05\n",
      "working on rate = 0.05\n",
      "working on rate = 0.05\n",
      "working on rate = 0.02\n",
      "working on rate = 0.02\n",
      "working on rate = 0.01\n",
      "working on rate = 0.01\n",
      "working on rate = 0.005\n",
      "working on rate = 0.005\n",
      "working on rate = 0.002\n",
      "working on rate = 0.002\n",
      "working on rate = 0.001\n",
      "working on rate = 0.001\n",
      "working on rate = 0.001\n",
      "working on rate = 0.0005\n",
      "working on rate = 0.0005\n",
      "working on rate = 0.0001\n",
      "working on rate = 0.0001\n"
     ]
    }
   ],
   "source": [
    "######## sound data\n",
    "mix = np.loadtxt('mix.dat').T\n",
    "\n",
    "Fs = 11025\n",
    "\n",
    "mix_stand = Standardize(mix)\n",
    "\n",
    "############ ICA\n",
    "W, Y = MaxLikelihood_ICA(mix_stand)\n",
    "\n",
    "Y_stand = Standardize(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "975a34d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing mixed track 0\n",
      "Playing mixed track 1\n",
      "Playing mixed track 2\n",
      "Playing mixed track 3\n",
      "Playing mixed track 4\n"
     ]
    }
   ],
   "source": [
    "######### play source\n",
    "for i in range(mix_stand.shape[0]):\n",
    "    print('Playing mixed track %d' % i)\n",
    "    sd.play(mix_stand[i,:], Fs, blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1f206a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing separated track 0\n",
      "Playing separated track 1\n",
      "Playing separated track 2\n",
      "Playing separated track 3\n",
      "Playing separated track 4\n"
     ]
    }
   ],
   "source": [
    "########## play IC\n",
    "\n",
    "for i in range(Y_stand.shape[0]):\n",
    "    print('Playing separated track %d' % i)\n",
    "    sd.play(Y_stand[i,:], Fs, blocking=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
